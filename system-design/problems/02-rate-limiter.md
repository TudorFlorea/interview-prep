# Design a Rate Limiter

[â† Back to Problems](/system-design/problems/00-index.md)

---

## ğŸ¯ Problem Statement

Design a rate limiting service that can restrict the number of requests a client can make within a time window.

**Difficulty**: ğŸŸ¢ Foundational (Tier 1)

---

## 1. Requirements Gathering

### Functional Requirements

1. **Limit requests** by various keys (user ID, IP, API key)
2. **Configurable limits** per endpoint or globally
3. **Return rate limit headers** (remaining, reset time)
4. **Support different limiting strategies** (fixed window, sliding window, token bucket)
5. **Graceful handling** when limit exceeded (429 response)

### Non-Functional Requirements (FCC-SLEDS)

| Aspect | Requirement |
|--------|-------------|
| **Fault Tolerance** | Fail open (allow) or fail closed (deny) on errors |
| **CAP** | AP preferred - eventual consistency acceptable |
| **Compliance** | Fair usage policies, SLA requirements |
| **Scalability** | Handle millions of requests per second |
| **Latency** | &lt; 1ms overhead per request |
| **Environment** | Distributed across multiple data centers |
| **Durability** | Counters can be reset on failure (not critical) |
| **Security** | Prevent bypass attacks |

---

## 2. Rate Limiting Algorithms

### Algorithm 1: Fixed Window Counter

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FIXED WINDOW COUNTER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Limit: 100 requests per minute                                 â”‚
â”‚                                                                 â”‚
â”‚  Window 1 (12:00-12:01)    Window 2 (12:01-12:02)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ â”‚    â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ â”‚              â”‚
â”‚  â”‚     80/100         â”‚    â”‚     45/100         â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â”‚  âœ… Simple to implement                                         â”‚
â”‚  âœ… Memory efficient                                            â”‚
â”‚  âŒ Burst at window edges                                       â”‚
â”‚     (100 at 12:00:59 + 100 at 12:01:01 = 200 in 2 seconds)     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
class FixedWindowCounter:
    def __init__(self, redis: Redis, limit: int, window_seconds: int):
        self.redis = redis
        self.limit = limit
        self.window = window_seconds
    
    def is_allowed(self, key: str) -> bool:
        # Get current window
        window_key = f"ratelimit:{key}:{int(time.time() // self.window)}"
        
        # Increment and check
        current = self.redis.incr(window_key)
        
        # Set expiry on first request
        if current == 1:
            self.redis.expire(window_key, self.window)
        
        return current <= self.limit
    
    def get_remaining(self, key: str) -> int:
        window_key = f"ratelimit:{key}:{int(time.time() // self.window)}"
        current = int(self.redis.get(window_key) or 0)
        return max(0, self.limit - current)
```

### Algorithm 2: Sliding Window Log

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SLIDING WINDOW LOG                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Store timestamp of each request                                â”‚
â”‚                                                                 â”‚
â”‚  Window: Last 60 seconds from NOW                               â”‚
â”‚                                                                 â”‚
â”‚  Timestamps stored:                                             â”‚
â”‚  [12:00:15, 12:00:23, 12:00:45, 12:01:02, 12:01:08]            â”‚
â”‚                                                                 â”‚
â”‚  Now: 12:01:10                                                  â”‚
â”‚  Window start: 12:00:10                                         â”‚
â”‚  Requests in window: [12:00:15, 12:00:23, 12:00:45, 12:01:02, 12:01:08]
â”‚  Count: 5                                                       â”‚
â”‚                                                                 â”‚
â”‚  âœ… Very accurate                                               â”‚
â”‚  âŒ High memory (stores all timestamps)                         â”‚
â”‚  âŒ Expensive cleanup                                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
class SlidingWindowLog:
    def __init__(self, redis: Redis, limit: int, window_seconds: int):
        self.redis = redis
        self.limit = limit
        self.window = window_seconds
    
    def is_allowed(self, key: str) -> bool:
        now = time.time()
        window_start = now - self.window
        redis_key = f"ratelimit:{key}"
        
        pipe = self.redis.pipeline()
        
        # Remove old timestamps
        pipe.zremrangebyscore(redis_key, 0, window_start)
        
        # Count current window
        pipe.zcard(redis_key)
        
        # Add current request
        pipe.zadd(redis_key, {str(now): now})
        
        # Set expiry
        pipe.expire(redis_key, self.window)
        
        results = pipe.execute()
        count = results[1]
        
        return count < self.limit
```

### Algorithm 3: Sliding Window Counter (Hybrid)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SLIDING WINDOW COUNTER                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Approximation using weighted average of two windows            â”‚
â”‚                                                                 â”‚
â”‚  Previous Window    Current Window                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚  â”‚    80 reqs   â”‚   â”‚    30 reqs   â”‚                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                                                 â”‚
â”‚  Current position: 25% into current window                      â”‚
â”‚                                                                 â”‚
â”‚  Weighted count = prev_count Ã— (1 - position%) + curr_count    â”‚
â”‚                 = 80 Ã— 0.75 + 30 Ã— 1.0                          â”‚
â”‚                 = 60 + 30 = 90                                  â”‚
â”‚                                                                 â”‚
â”‚  âœ… Memory efficient (just 2 counters)                          â”‚
â”‚  âœ… Good accuracy                                               â”‚
â”‚  âœ… No burst at edges                                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
class SlidingWindowCounter:
    def __init__(self, redis: Redis, limit: int, window_seconds: int):
        self.redis = redis
        self.limit = limit
        self.window = window_seconds
    
    def is_allowed(self, key: str) -> bool:
        now = time.time()
        current_window = int(now // self.window)
        prev_window = current_window - 1
        
        # Position within current window (0.0 to 1.0)
        position = (now % self.window) / self.window
        
        # Get both counters
        prev_count = int(self.redis.get(f"ratelimit:{key}:{prev_window}") or 0)
        curr_count = int(self.redis.get(f"ratelimit:{key}:{current_window}") or 0)
        
        # Weighted count
        weighted = prev_count * (1 - position) + curr_count
        
        if weighted >= self.limit:
            return False
        
        # Increment current window
        pipe = self.redis.pipeline()
        pipe.incr(f"ratelimit:{key}:{current_window}")
        pipe.expire(f"ratelimit:{key}:{current_window}", self.window * 2)
        pipe.execute()
        
        return True
```

### Algorithm 4: Token Bucket

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TOKEN BUCKET                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Bucket: capacity = 10, refill_rate = 1 token/second            â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ â— â— â— â— â— â— â—‹ â—‹ â—‹ â—‹  â”‚  6 tokens available                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚           â†‘                                                     â”‚
â”‚     Tokens added                                                â”‚
â”‚     at refill_rate                                              â”‚
â”‚                                                                 â”‚
â”‚  Request arrives:                                               â”‚
â”‚  â€¢ Has tokens? Remove 1 token, allow request                    â”‚
â”‚  â€¢ No tokens? Reject request                                    â”‚
â”‚                                                                 â”‚
â”‚  âœ… Allows short bursts (up to bucket capacity)                 â”‚
â”‚  âœ… Smooth rate over time                                       â”‚
â”‚  âœ… Memory efficient                                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
class TokenBucket:
    def __init__(self, redis: Redis, capacity: int, refill_rate: float):
        self.redis = redis
        self.capacity = capacity
        self.refill_rate = refill_rate  # tokens per second
    
    def is_allowed(self, key: str) -> bool:
        now = time.time()
        redis_key = f"tokenbucket:{key}"
        
        # Lua script for atomic operation
        lua_script = """
        local key = KEYS[1]
        local capacity = tonumber(ARGV[1])
        local refill_rate = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        
        local data = redis.call('HMGET', key, 'tokens', 'last_update')
        local tokens = tonumber(data[1]) or capacity
        local last_update = tonumber(data[2]) or now
        
        -- Calculate tokens to add
        local elapsed = now - last_update
        local new_tokens = math.min(capacity, tokens + elapsed * refill_rate)
        
        -- Try to consume token
        if new_tokens >= 1 then
            new_tokens = new_tokens - 1
            redis.call('HMSET', key, 'tokens', new_tokens, 'last_update', now)
            redis.call('EXPIRE', key, 3600)
            return 1
        else
            return 0
        end
        """
        
        result = self.redis.eval(
            lua_script, 
            1, 
            redis_key,
            self.capacity,
            self.refill_rate,
            now
        )
        
        return result == 1
```

### Algorithm 5: Leaky Bucket

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LEAKY BUCKET                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Requests queue up, processed at constant rate                  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚ â”€â–º [req4]            â”‚  Queue (bucket)                       â”‚
â”‚  â”‚    [req3]            â”‚                                       â”‚
â”‚  â”‚    [req2]            â”‚                                       â”‚
â”‚  â”‚    [req1]            â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼ (leak at constant rate)                            â”‚
â”‚      â”€â–º Processed                                               â”‚
â”‚                                                                 â”‚
â”‚  âœ… Smooth output rate                                          â”‚
â”‚  âœ… No bursts                                                   â”‚
â”‚  âŒ Adds latency (requests wait in queue)                       â”‚
â”‚  âŒ Queue can grow during bursts                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Algorithm Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ALGORITHM COMPARISON                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Algorithm       â”‚ Memory   â”‚ Accuracy â”‚ Bursts   â”‚ Use Case    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Fixed Window    â”‚ Low      â”‚ Low      â”‚ Yes      â”‚ Simple apps â”‚
â”‚ Sliding Log     â”‚ High     â”‚ High     â”‚ No       â”‚ Low volume  â”‚
â”‚ Sliding Counter â”‚ Low      â”‚ Medium   â”‚ No       â”‚ Most APIs   â”‚
â”‚ Token Bucket    â”‚ Low      â”‚ High     â”‚ Allowed  â”‚ Flexible    â”‚
â”‚ Leaky Bucket    â”‚ Medium   â”‚ High     â”‚ Smoothed â”‚ Queued work â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. High-Level Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         RATE LIMITER ARCHITECTURE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                            â”‚
â”‚     â”‚  Client  â”‚                                                            â”‚
â”‚     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                            â”‚
â”‚          â”‚ Request with API Key / User ID                                   â”‚
â”‚          â–¼                                                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚     â”‚ Load Balancer â”‚                                                       â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚             â”‚                                                               â”‚
â”‚             â–¼                                                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚     â”‚                    API GATEWAY                                 â”‚      â”‚
â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚     â”‚  â”‚                 RATE LIMITER MIDDLEWARE                  â”‚  â”‚      â”‚
â”‚     â”‚  â”‚                                                          â”‚  â”‚      â”‚
â”‚     â”‚  â”‚  1. Extract key (user_id, ip, api_key)                  â”‚  â”‚      â”‚
â”‚     â”‚  â”‚  2. Check rate limit                                     â”‚  â”‚      â”‚
â”‚     â”‚  â”‚  3. Allow or reject (429)                                â”‚  â”‚      â”‚
â”‚     â”‚  â”‚                                                          â”‚  â”‚      â”‚
â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚     â”‚                            â”‚                                   â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                  â”‚                                          â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚                           â”‚                            â”‚
â”‚              (If allowed)                (If rejected)                      â”‚
â”‚                    â”‚                           â”‚                            â”‚
â”‚                    â–¼                           â–¼                            â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚            â”‚   Backend   â”‚             â”‚ 429 Responseâ”‚                     â”‚
â”‚            â”‚   Service   â”‚             â”‚ Too Many    â”‚                     â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚ Requests    â”‚                     â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚     â”‚                    RATE LIMIT STORAGE                          â”‚      â”‚
â”‚     â”‚                                                                â”‚      â”‚
â”‚     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚      â”‚
â”‚     â”‚    â”‚   Redis 1   â”‚â”€â”€â”€â”€â”‚   Redis 2   â”‚â”€â”€â”€â”€â”‚   Redis 3   â”‚     â”‚      â”‚
â”‚     â”‚    â”‚  (Primary)  â”‚    â”‚  (Replica)  â”‚    â”‚  (Replica)  â”‚     â”‚      â”‚
â”‚     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      â”‚
â”‚     â”‚                                                                â”‚      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Rate Limit Rules Configuration

```yaml
# Rate limit configuration
rate_limits:
  # Default limits
  default:
    requests_per_minute: 60
    requests_per_hour: 1000
  
  # Per endpoint limits
  endpoints:
    - path: "/api/login"
      method: "POST"
      limit: 5
      window: "1m"
      key: "ip"  # Rate limit by IP for login
    
    - path: "/api/search"
      method: "GET"
      limit: 30
      window: "1m"
      key: "user_id"
    
    - path: "/api/upload"
      method: "POST"
      limit: 10
      window: "1h"
      key: "user_id"
  
  # Tier-based limits
  tiers:
    free:
      requests_per_minute: 30
      requests_per_day: 1000
    
    pro:
      requests_per_minute: 100
      requests_per_day: 10000
    
    enterprise:
      requests_per_minute: 1000
      requests_per_day: 100000
```

```python
class RateLimitRule:
    path_pattern: str
    method: str
    limit: int
    window_seconds: int
    key_type: str  # 'user_id', 'ip', 'api_key'
    tier_overrides: Dict[str, int]

class RateLimiterService:
    def __init__(self, redis: Redis, rules: List[RateLimitRule]):
        self.redis = redis
        self.rules = rules
        self.default_limiter = SlidingWindowCounter(redis, 60, 60)
    
    def check_rate_limit(self, request: Request, user: User) -> RateLimitResult:
        # Find matching rule
        rule = self.find_rule(request.path, request.method)
        
        if not rule:
            rule = self.default_rule
        
        # Determine limit based on user tier
        limit = rule.tier_overrides.get(user.tier, rule.limit)
        
        # Build key
        key = self.build_key(rule, request, user)
        
        # Check limit
        limiter = SlidingWindowCounter(self.redis, limit, rule.window_seconds)
        allowed = limiter.is_allowed(key)
        remaining = limiter.get_remaining(key)
        
        return RateLimitResult(
            allowed=allowed,
            limit=limit,
            remaining=remaining,
            reset_at=self.calculate_reset_time(rule.window_seconds)
        )
```

---

## 5. Response Headers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RATE LIMIT HEADERS                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Standard Headers:                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚                                                                 â”‚
â”‚  X-RateLimit-Limit: 100           # Max requests allowed        â”‚
â”‚  X-RateLimit-Remaining: 45        # Requests remaining          â”‚
â”‚  X-RateLimit-Reset: 1699012800    # Unix timestamp of reset     â”‚
â”‚                                                                 â”‚
â”‚  On 429 Too Many Requests:                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚                                                                 â”‚
â”‚  Retry-After: 30                  # Seconds until retry         â”‚
â”‚  X-RateLimit-Limit: 100                                         â”‚
â”‚  X-RateLimit-Remaining: 0                                       â”‚
â”‚  X-RateLimit-Reset: 1699012800                                  â”‚
â”‚                                                                 â”‚
â”‚  Response Body:                                                 â”‚
â”‚  {                                                              â”‚
â”‚    "error": "rate_limit_exceeded",                              â”‚
â”‚    "message": "Too many requests. Retry after 30 seconds.",     â”‚
â”‚    "retry_after": 30                                            â”‚
â”‚  }                                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
@app.middleware("http")
async def rate_limit_middleware(request: Request, call_next):
    user = get_current_user(request)
    result = rate_limiter.check_rate_limit(request, user)
    
    # Set headers on all responses
    response_headers = {
        "X-RateLimit-Limit": str(result.limit),
        "X-RateLimit-Remaining": str(result.remaining),
        "X-RateLimit-Reset": str(int(result.reset_at.timestamp()))
    }
    
    if not result.allowed:
        retry_after = int((result.reset_at - datetime.now()).total_seconds())
        return JSONResponse(
            status_code=429,
            headers={
                **response_headers,
                "Retry-After": str(retry_after)
            },
            content={
                "error": "rate_limit_exceeded",
                "message": f"Too many requests. Retry after {retry_after} seconds.",
                "retry_after": retry_after
            }
        )
    
    response = await call_next(request)
    
    for key, value in response_headers.items():
        response.headers[key] = value
    
    return response
```

---

## 6. Distributed Rate Limiting

### Challenge: Multiple Servers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DISTRIBUTED CHALLENGE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Problem: Limit is 100/min, but we have 10 servers              â”‚
â”‚                                                                 â”‚
â”‚       Server 1  Server 2  Server 3  ...  Server 10              â”‚
â”‚       â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€       â”€â”€â”€â”€â”€â”€â”€                 â”‚
â”‚       count=15  count=12  count=20      count=18                â”‚
â”‚                                                                 â”‚
â”‚  Each server sees partial view!                                 â”‚
â”‚  User could make 150 requests (15 to each server)               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solution 1: Centralized Redis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CENTRALIZED REDIS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  All servers share single Redis for rate limiting               â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚ Server 1 â”‚â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Server 2 â”‚â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–ºâ”‚ Redis Cluster  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â”‚ (Rate Limits)  â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚  â”‚ Server 3 â”‚â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚                                                                 â”‚
â”‚  âœ… Accurate global count                                       â”‚
â”‚  âŒ Redis becomes bottleneck                                    â”‚
â”‚  âŒ Network latency on every request                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solution 2: Local + Sync

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LOCAL + PERIODIC SYNC                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Each server tracks locally, syncs periodically                 â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ Server 1         â”‚                                           â”‚
â”‚  â”‚ Local: 15        â”‚â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ Global est: 150  â”‚      â”‚                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      â”‚                 â”‚          â”‚
â”‚  â”‚ Server 2         â”‚      â”œâ”€â”€â”€â”€â”€â–ºâ”‚  Redis (sync)   â”‚          â”‚
â”‚  â”‚ Local: 12        â”‚      â”‚      â”‚                 â”‚          â”‚
â”‚  â”‚ Global est: 150  â”‚â”€â”€â”€â”€â”€â”€â”¤      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚      Sync every 1 second          â”‚
â”‚  â”‚ Server 3         â”‚      â”‚                                    â”‚
â”‚  â”‚ Local: 20        â”‚â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚  â”‚ Global est: 150  â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                                 â”‚
â”‚  âœ… Low latency (local check)                                   â”‚
â”‚  âŒ Less accurate (sync delay)                                  â”‚
â”‚  âŒ Can exceed limit briefly                                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solution 3: Sticky Sessions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STICKY SESSIONS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Route same user to same server (by user_id hash)               â”‚
â”‚                                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚  User A â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚             â”‚                              â”‚
â”‚  (hash % 3 = 0)    â”‚             â”‚â”€â”€â”€â”€â”€â”€â–º Server 1              â”‚
â”‚                    â”‚    Load     â”‚                              â”‚
â”‚  User B â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Balancer   â”‚â”€â”€â”€â”€â”€â”€â–º Server 2              â”‚
â”‚  (hash % 3 = 1)    â”‚             â”‚                              â”‚
â”‚                    â”‚ (Consistent â”‚â”€â”€â”€â”€â”€â”€â–º Server 3              â”‚
â”‚  User C â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Hashing)  â”‚                              â”‚
â”‚  (hash % 3 = 2)    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                 â”‚
â”‚  âœ… Each server has complete view of its users                  â”‚
â”‚  âœ… No cross-server coordination                                â”‚
â”‚  âŒ Hot users can overload one server                          â”‚
â”‚  âŒ Server failure affects subset of users                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solution 4: Redis Cluster with Sharding

```python
class DistributedRateLimiter:
    def __init__(self, redis_cluster: RedisCluster):
        self.redis = redis_cluster
    
    def is_allowed(self, key: str) -> bool:
        # Key automatically routed to correct shard
        # Redis Cluster handles sharding by key
        
        # Use Lua script for atomic operation
        lua_script = """
        local key = KEYS[1]
        local limit = tonumber(ARGV[1])
        local window = tonumber(ARGV[2])
        local now = tonumber(ARGV[3])
        
        local current = redis.call('INCR', key)
        
        if current == 1 then
            redis.call('EXPIRE', key, window)
        end
        
        if current <= limit then
            return {1, limit - current}  -- allowed, remaining
        else
            return {0, 0}  -- denied, 0 remaining
        end
        """
        
        window_key = f"ratelimit:{key}:{int(time.time() // 60)}"
        
        result = self.redis.eval(
            lua_script,
            1,
            window_key,
            100,  # limit
            60,   # window
            time.time()
        )
        
        return result[0] == 1
```

---

## 7. Race Condition Handling

### The Read-Modify-Write Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RACE CONDITION                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Two requests arrive simultaneously                             â”‚
â”‚                                                                 â”‚
â”‚  Time     Request A           Request B                         â”‚
â”‚  â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  T1       Read: count=99      Read: count=99                    â”‚
â”‚  T2       Check: 99<100 âœ“     Check: 99<100 âœ“                   â”‚
â”‚  T3       Write: count=100    Write: count=100                  â”‚
â”‚  T4       Allow               Allow                             â”‚
â”‚                                                                 â”‚
â”‚  Result: Both allowed, but count should be 101 (over limit!)    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solution: Lua Scripts (Atomic Operations)

```python
# All operations in single atomic Lua script
RATE_LIMIT_SCRIPT = """
local key = KEYS[1]
local limit = tonumber(ARGV[1])
local window = tonumber(ARGV[2])

-- Atomic increment
local current = redis.call('INCR', key)

-- Set expiry only on first request
if current == 1 then
    redis.call('EXPIRE', key, window)
end

-- Check limit
if current > limit then
    return {0, 0, redis.call('TTL', key)}  -- denied
else
    return {1, limit - current, redis.call('TTL', key)}  -- allowed
end
"""

class AtomicRateLimiter:
    def __init__(self, redis: Redis):
        self.redis = redis
        self.script = self.redis.register_script(RATE_LIMIT_SCRIPT)
    
    def check(self, key: str, limit: int, window: int) -> RateLimitResult:
        result = self.script(
            keys=[f"ratelimit:{key}"],
            args=[limit, window]
        )
        
        return RateLimitResult(
            allowed=result[0] == 1,
            remaining=result[1],
            reset_in_seconds=result[2]
        )
```

---

## 8. Fault Tolerance

### What Happens When Redis is Down?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FAILURE HANDLING                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Option 1: Fail Open (Allow all)                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  If Redis down â†’ allow requests                                 â”‚
â”‚  â€¢ Better user experience                                       â”‚
â”‚  â€¢ Risk of abuse during outage                                  â”‚
â”‚  â€¢ Use for non-critical limits                                  â”‚
â”‚                                                                 â”‚
â”‚  Option 2: Fail Closed (Deny all)                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  If Redis down â†’ reject requests                                â”‚
â”‚  â€¢ Protects backend                                             â”‚
â”‚  â€¢ Bad user experience                                          â”‚
â”‚  â€¢ Use for critical protection                                  â”‚
â”‚                                                                 â”‚
â”‚  Option 3: Local Fallback                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  If Redis down â†’ use local in-memory limiter                    â”‚
â”‚  â€¢ Graceful degradation                                         â”‚
â”‚  â€¢ Less accurate but functional                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
class ResilientRateLimiter:
    def __init__(self, redis: Redis):
        self.redis = redis
        self.local_limiter = LocalTokenBucket()
        self.fail_open = True  # Configuration
    
    async def is_allowed(self, key: str) -> bool:
        try:
            return await asyncio.wait_for(
                self.check_redis(key),
                timeout=0.1  # 100ms timeout
            )
        except (RedisError, asyncio.TimeoutError) as e:
            logger.warning(f"Redis rate limit failed: {e}")
            metrics.increment("rate_limiter.fallback")
            
            if self.fail_open:
                # Fall back to local limiter
                return self.local_limiter.is_allowed(key)
            else:
                return False  # Fail closed
    
    async def check_redis(self, key: str) -> bool:
        # Normal Redis check
        ...
```

---

## 9. Multi-Region Rate Limiting

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GLOBAL RATE LIMITING                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Challenge: User limit is 1000/min globally                     â”‚
â”‚  User makes requests from US, EU, and Asia simultaneously       â”‚
â”‚                                                                 â”‚
â”‚  Option 1: Single Global Redis                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚                                                                 â”‚
â”‚      US-East        EU-West        AP-South                     â”‚
â”‚         â”‚              â”‚              â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                        â–¼                                        â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚               â”‚ Global Redis â”‚  (high latency)                  â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                 â”‚
â”‚  Option 2: Partitioned Limits                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  Global limit = 1000/min                                        â”‚
â”‚  US = 400/min, EU = 400/min, AP = 200/min                      â”‚
â”‚                                                                 â”‚
â”‚      US-East           EU-West           AP-South               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚ Redis    â”‚      â”‚ Redis    â”‚      â”‚ Redis    â”‚            â”‚
â”‚    â”‚ 400/min  â”‚      â”‚ 400/min  â”‚      â”‚ 200/min  â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                 â”‚
â”‚  Option 3: Async Aggregation                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  â€¢ Local limits per region                                      â”‚
â”‚  â€¢ Async sync of totals                                         â”‚
â”‚  â€¢ Adjust local limits based on global usage                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 10. Interview Tips

### Common Questions

1. **Why not just use local counters?**
   - Inaccurate in distributed systems
   - User can hit multiple servers

2. **How do you handle bursts?**
   - Token bucket allows controlled bursts
   - Sliding window prevents edge bursts

3. **What about DDoS attacks?**
   - Rate limiting is one layer
   - Also need WAF, IP blocking
   - Limit at edge (CDN level)

4. **How do you test rate limiting?**
   - Load testing tools
   - Verify headers are correct
   - Test edge cases (reset timing)

5. **Can users bypass by changing IP?**
   - Rate limit by multiple keys
   - User ID (after auth)
   - Device fingerprinting
   - CAPTCHA as fallback

---

## âœ… Key Takeaways

1. **Choose algorithm by use case** - Token bucket for bursts, sliding window for accuracy
2. **Use Lua scripts** - Atomic operations prevent race conditions
3. **Plan for failure** - Fail open vs closed based on criticality
4. **Return proper headers** - Limit, Remaining, Reset, Retry-After
5. **Distributed is hard** - Use centralized Redis or partition limits
6. **Multiple keys** - Combine user ID, IP, and API key
7. **Config-driven rules** - Different limits per endpoint/tier

---

## ğŸ“š Related Topics

- [Rate Limiting Fundamentals](/system-design/fundamentals/18-rate-limiting.md) - Deep dive on algorithms
- [Caching](/system-design/fundamentals/07-caching.md) - Redis patterns
- [Distributed Patterns](/system-design/fundamentals/14-distributed-patterns.md) - Consensus for distributed limits
- [URL Shortener](/system-design/problems/01-url-shortener.md) - Uses rate limiting
